var documenterSearchIndex = {"docs":
[{"location":"metrics.html#Econometrics-1","page":"Econometrics","title":"Econometrics","text":"","category":"section"},{"location":"metrics.html#","page":"Econometrics","title":"Econometrics","text":"This set of methods is concerned with inference about an SMM.MAlgoBGP\nThis is mostly standard GMM technology","category":"page"},{"location":"metrics.html#","page":"Econometrics","title":"Econometrics","text":"Modules = [SMM]\nPages = [\"econometrics.jl\"]","category":"page"},{"location":"metrics.html#SMM.FD_gradient-Tuple{MProb,Union{Dict, OrderedDict}}","page":"Econometrics","title":"SMM.FD_gradient","text":"FD_gradient(m::MProb,p::Dict;step_perc=0.005,diff_method=:forward)\n\nGet the gradient of the moment function wrt to some parameter vector via finite difference approximation.  The output is a (k,n) matrix, where k is the number of m.params_to_sample and where m is the number of moments.\n\nstep_perc: step size in percent of parameter\ndiff_method: :forward or :central differencing\nuse_range: compute the step as a percentage of the parameter range (true), or not\n\nThe default step size is 1% of the parameter range.\n\n\n\n\n\n","category":"method"},{"location":"metrics.html#SMM.getSigma-Tuple{MProb,Union{Dict, OrderedDict},Int64}","page":"Econometrics","title":"SMM.getSigma","text":"getSigma(m::MProb,p::Union{Dict,OrderedDict},reps::Int)\n\nComputes var-cov matrix of simulated data. This requires to unseed the random shock sequences in the objective function (to generate randomly different moments in each run). Argument reps controls how many samples of different moment functions should be taken.\n\n\n\n\n\n","category":"method"},{"location":"metrics.html#SMM.get_stdErrors-Tuple{MProb,Union{Dict, OrderedDict}}","page":"Econometrics","title":"SMM.get_stdErrors","text":"get_stdErrors(m::MProb,p::Union{Dict,OrderedDict};reps=300)\n\nComputes standard errors according to standard sandwich formula:\n\nS = (J W J)^-1 (J W Sigma W J) (J W J)^-1\n\nwhere \n\nSigma is the data var-cov matrix generated by drawing H samples of simulated data using p. each draw has a different shock sequence here. this is done in function getSigma.\nJ is the gradient of the objective function obtained with FD_gradient\nW is the weighting matrix.\n\n\n\n\n\n","category":"method"},{"location":"slices.html#slices-1","page":"Slices","title":"Slices from a MProb","text":"","category":"section"},{"location":"slices.html#","page":"Slices","title":"Slices","text":"Modules = [SMM]\nPages = [\"slices.jl\"]","category":"page"},{"location":"slices.html#SMM.doSlices","page":"Slices","title":"SMM.doSlices","text":"doSlices(m::MProb,npoints::Int,parallel=false)\n\nComputes Slices of an MProb\n\n\n\n\n\n","category":"function"},{"location":"slices.html#SMM.Slice","page":"Slices","title":"SMM.Slice","text":"A slice in dimension j of a function f in mathbbR^N is defined as f(p1pjpN), where p is the initial parameter vector and p[j] = range(lower[j], stop = upper[j], length = npoints), where lower[j],upper[j] are the bounds of the parameter space in dimension j.\n\nFields\n\nres: Dict of resulting slices. For each parameter p_j there is a Dict with as many entries as npoints chosen in doSlices\np0: Initial parameter vector dict\nm0: data moments dict\n\nExamples\n\njulia> m = MProb()\njulia> p = OrderedDict(:p1=>1.1,:p2=>pi)\njulia> m = OrderedDict(:m1=>rand(),:m2=>e)\njulia> Slice(p,m)\n\n\n\n\n\n\n","category":"type"},{"location":"slices.html#SMM.optSlices-Tuple{MProb,Int64}","page":"Slices","title":"SMM.optSlices","text":"optSlices(m::MProb,npoints::Int;parallel=false,tol=1e-5,update=nothing,filename=\"trace.jld2\")\n\nComputes Slices of an MProb and keeps the best value from each slice. This implements a naive form of cyclic coordinate descent in that it optimizes wrt to one direction at a time, keeping the best value. It's naive because it does a grid search in that direction (and disregards any gradient information). The grid size shrinks, however, at a rate update (constant by default)\n\nAlgorithm Description\n\nLet theta in mathbbR^K be the parameter vector of objective function L(theta). A cyclic coordinate search algorithm defines cycle n+1 as follows:\n\nbeginalign*\ntheta^(n+1)_1  =argmin_theta_1 L(theta_1theta_2^(n)dotstheta_K^(n))\ntheta^(n+1)_2  =argmin_theta_2 L(theta_1^(n)theta_2theta_3^(n)dotstheta_K^(n))\ntheta^(n+1)_3  =argmin_theta_3 L(theta_1^(n)theta_2^(n)theta_3theta_4^(n)dotstheta_K^(n))\n  vdots\ntheta^(n+1)_K  =argmin_theta_K L(theta_1^(n)theta_2^(n)dotstheta_K)\nendalign*\n\nThe algorithm runs until a convergence criterion is met; here we stop at cycle n if the norm of the distance between theta^(n-1) and theta^(n) is less than tol.\n\n\n\n\n\n","category":"method"},{"location":"eval.html#eval_type-1","page":"Eval Object","title":"Eval Type","text":"","category":"section"},{"location":"eval.html#","page":"Eval Object","title":"Eval Object","text":"This is a datatype to track function evaluations:","category":"page"},{"location":"eval.html#","page":"Eval Object","title":"Eval Object","text":"Modules = [SMM]\nPages = [\"Eval.jl\"]","category":"page"},{"location":"eval.html#SMM.Eval","page":"Eval Object","title":"SMM.Eval","text":"Eval type for managing function evaluations\n\nfields\n\nvalue: current function value\ntime: timing of evaluation\nparams: OrderedDict of parameters\nsimMoments: OrderedDict of moments generated by model\ndataMoments: OrderedDict of data moments\ndataMomentsW: OrderedDict of weights for data moments\nstatus: Int error status\nprob: probability of acceptance\naccepted: whether draw was accepted\noptions: Dict of options and other info\n\n\n\n\n\n","category":"type"},{"location":"eval.html#SMM.dataMomentd-Tuple{Eval}","page":"Eval Object","title":"SMM.dataMomentd","text":"dataMomentd(ev::Eval)\n\nObtain all data momoents as dict\n\n\n\n\n\n","category":"method"},{"location":"eval.html#SMM.check_moments-Tuple{Eval}","page":"Eval Object","title":"SMM.check_moments","text":"check_moments(ev::Eval)\n\nreturns all data and simluated moments of a single Eval as a dataframe.\n\n\n\n\n\n","category":"method"},{"location":"eval.html#SMM.dataMomentWd-Tuple{Eval}","page":"Eval Object","title":"SMM.dataMomentWd","text":"Obtain all moment weights as dict\n\n\n\n\n\n","category":"method"},{"location":"examples.html#Examples-1","page":"Examples","title":"Examples","text":"","category":"section"},{"location":"examples.html#Estimating-Means-of-a-bivariate-normal-1","page":"Examples","title":"Estimating Means of a bivariate normal","text":"","category":"section"},{"location":"examples.html#","page":"Examples","title":"Examples","text":"Let's define a function that returns a Normal distribution with a certain location, and let's call this our model:","category":"page"},{"location":"examples.html#","page":"Examples","title":"Examples","text":"m(p) = mathcalNleft( p_1p_2^T  I_2 right)","category":"page"},{"location":"examples.html#","page":"Examples","title":"Examples","text":"Our aim will be to estimate the location of two means from data that is simulated from this law with an MCMC chain, given some true p. (Of course the sample mean would be a perfectly valid estimator.)  The twist here is that we will pretend that we don't have access to the entire simulated dataset ","category":"page"},{"location":"examples.html#","page":"Examples","title":"Examples","text":"X_i_i=1^N X_i = (x_i1x_i2) sim m(p)","category":"page"},{"location":"examples.html#","page":"Examples","title":"Examples","text":"but only a set of summary statistics S - in our case, we'd have two moments of this data, namely mu_j = frac1Nx_ijj=12. Our objective function is the squared distance between mu, and what our model produces instead. That is, we give a parameter vector p to our model m, which in turn produces 2 simulated moments denoted mu. Finally, we assess their respective distance - we want to eventuall find p approx p.","category":"page"},{"location":"examples.html#","page":"Examples","title":"Examples","text":"Again: ","category":"page"},{"location":"examples.html#","page":"Examples","title":"Examples","text":"Assume true moments mu (and, hence, true p)\nrepeatedly create data from m(p) for different p drawn from a space -33 times -22. For each dataset, compute mu_j = frac1Nx_ijj=12.\nCompute distance mumu and decide according to the SMM.MAlgoBGP algorithm whether to accept or reject current p. ","category":"page"},{"location":"examples.html#","page":"Examples","title":"Examples","text":"julia> using SMM\njulia> pb    = OrderedDict(\"p1\" => [0.2,-3,3] , \"p2\" => [-0.2,-2,2] )  # param spaces\njulia> moms  = DataFrame(name=[\"mu1\",\"mu2\"],value=[-1.0,1.0],weight=ones(2))  # truth\njulia> mprob = MProb() \njulia> addSampledParam!(mprob,pb) \njulia> addMoment!(mprob,moms) \njulia> addEvalFunc!(mprob,objfunc_norm)\n\njulia> nchains = 3\n\njulia> opts =Dict(\"N\"=>nchains,\n    \"maxiter\"=> 10,\n    \"maxtemp\"=> 5,\n    \"coverage\"=>0.025,\n    \"sigma_update_steps\"=>10, \n    \"sigma_adjust_by\"=>0.01, \n    \"smpl_iters\"=>1000,\n    \"parallel\"=>true, \n    \"min_improve\"=>[0.05 for i in 1:nchains], \n    \"mixprob\"=>0.3, \n    \"acc_tuners\"=>[12.0 for i in 1:nchains], \n    \"animate\"=>false)\n\njulia> MA = MAlgoBGP(mprob,opts)\n\nBGP Algorithm with 3 BGPChains\n============================\n\nAlgorithm\n---------\nCurrent iteration: 0\nNumber of params to estimate: 2\nNumber of moments to match: 2\n\njulia> run!(MA)\n[ Info: Starting estimation loop.\nProgress: 100%|████████████████████████████████████████| Time: 0:00:04\n┌ Warning: could not find 'filename' in algo.opts\n└ @ SMM ~/.julia/v0.6/SMM/src/mopt/AlgoAbstract.jl:69\n[ Info: Done with estimation after 0.1 minutes\n","category":"page"},{"location":"examples.html#","page":"Examples","title":"Examples","text":"Full list of options is available at the SMM.BGPChain documentation","category":"page"},{"location":"examples.html#Diagnostic-tools-1","page":"Examples","title":"Diagnostic tools","text":"","category":"section"},{"location":"examples.html#","page":"Examples","title":"Examples","text":"For this running example, here are a couple of plots that can easily be generated with the package.","category":"page"},{"location":"examples.html#.-Objective-function-and-param-values-history-1","page":"Examples","title":"1. Objective function and param values history","text":"","category":"section"},{"location":"examples.html#","page":"Examples","title":"Examples","text":"This can be generated via plot(MA.chains[1]) (i.e. plots the first chain). MA is the final object of the above example.","category":"page"},{"location":"examples.html#","page":"Examples","title":"Examples","text":"(Image: )","category":"page"},{"location":"examples.html#.-Histograms-of-parameter-values-1","page":"Examples","title":"2. Histograms of parameter values","text":"","category":"section"},{"location":"examples.html#","page":"Examples","title":"Examples","text":"Plot a histogram of all accepted parameter values:","category":"page"},{"location":"examples.html#","page":"Examples","title":"Examples","text":"histogram(MA.chains[1])","category":"page"},{"location":"examples.html#","page":"Examples","title":"Examples","text":"(Image: )","category":"page"},{"location":"examples.html#.-Slices-through-objective-and-moment-functions-1","page":"Examples","title":"3. Slices through objective and moment functions","text":"","category":"section"},{"location":"examples.html#","page":"Examples","title":"Examples","text":"This can be generated via","category":"page"},{"location":"examples.html#","page":"Examples","title":"Examples","text":"s = doSlices(mprob,30)\nplot(s,:value)  # plot objective function over param values\nplot(s,:mu1)  # plot value of moment :mu1 over param values\nplot(s,:mu2)  # plot value of moment :mu2 over param values","category":"page"},{"location":"examples.html#","page":"Examples","title":"Examples","text":"The moment function plots show with red dashes the true moment value, and how the corresponding simulated moment changes as we move parameter p. This basically illustrates how and whether moment m_i contributes to the identification of the model.","category":"page"},{"location":"examples.html#","page":"Examples","title":"Examples","text":"(Image: moment function m1)","category":"page"},{"location":"examples.html#","page":"Examples","title":"Examples","text":"(Image: moment function m2)","category":"page"},{"location":"examples.html#","page":"Examples","title":"Examples","text":"Finally, the slice through the objective function illustrates whether we attain a local maximum (in this case at the true parameter values p = (-11)).","category":"page"},{"location":"examples.html#","page":"Examples","title":"Examples","text":"(Image: slices)","category":"page"},{"location":"examples.html#.-Tracking-proposals-1","page":"Examples","title":"4. Tracking proposals","text":"","category":"section"},{"location":"examples.html#","page":"Examples","title":"Examples","text":"The variance of the SMM.proposal kernel is updated every sigma_update_steps as set in the opts for the SMM.MAlgo.\nThere is a plotting method which can generate a gif of its evolution.\nJust set animate = true in the opts, e.g.","category":"page"},{"location":"examples.html#","page":"Examples","title":"Examples","text":"opts =Dict(\"N\"=>nchains,\n    \"maxiter\"=>200,\n    \"maxtemp\"=> 5,\n    \"smpl_iters\"=>1000,\n    \"parallel\"=>false,\n    \"min_improve\"=>[0.0 for i in 1:nchains],\n    \"acc_tuners\"=>[20;2;1.0],\n    \"animate\"=>true)","category":"page"},{"location":"examples.html#","page":"Examples","title":"Examples","text":"In the current example, this yields","category":"page"},{"location":"examples.html#","page":"Examples","title":"Examples","text":"(Image: proposals)","category":"page"},{"location":"algo.html#algos-1","page":"Moment Algorithms","title":"Moment Optimization Algorithms","text":"","category":"section"},{"location":"algo.html#","page":"Moment Algorithms","title":"Moment Algorithms","text":"Modules = [SMM]\nPages = [\"AlgoAbstract.jl\"]","category":"page"},{"location":"algo.html#SMM.MAlgo","page":"Moment Algorithms","title":"SMM.MAlgo","text":"This abstract type nests all MProb algorithms, for example SMM.MAlgoBGP\n\n\n\n\n\n","category":"type"},{"location":"algo.html#SMM.readMalgo-Tuple{AbstractString}","page":"Moment Algorithms","title":"SMM.readMalgo","text":"readMalgo(filename::AbstractString)\n\nLoad MAlgo from disk\n\n\n\n\n\n","category":"method"},{"location":"algo.html#SMM.run!-Tuple{MAlgo}","page":"Moment Algorithms","title":"SMM.run!","text":"run!( algo::MAlgo )\n\nFunction to start estimation of an MAlgo.\n\n\n\n\n\n","category":"method"},{"location":"algo.html#SMM.save-Tuple{MAlgo,AbstractString}","page":"Moment Algorithms","title":"SMM.save","text":"save(algo::MAlgo, filename::AbstractString)\n\nSave MAlgo to disk using JLD2\n\n\n\n\n\n","category":"method"},{"location":"algo.html#","page":"Moment Algorithms","title":"Moment Algorithms","text":"A particular implementation of such an algorithm is the BGP algorithm:","category":"page"},{"location":"algo.html#BGP-Algorithm-1","page":"Moment Algorithms","title":"BGP Algorithm","text":"","category":"section"},{"location":"algo.html#","page":"Moment Algorithms","title":"Moment Algorithms","text":"Modules = [SMM]\nPages = [\"AlgoBGP.jl\"]","category":"page"},{"location":"algo.html#SMM.MAlgoBGP","page":"Moment Algorithms","title":"SMM.MAlgoBGP","text":"MAlgoBGP: BGP MCMC Algorithm\n\nThis implements the BGP MCMC Algorithm Likelihood-Free Parallel Tempering by Baragatti, Grimaud and Pommeret (BGP):\n\nApproximate Bayesian Computational (ABC) methods (or likelihood-free methods) have appeared in the past fifteen years as useful methods to perform Bayesian analyses when the likelihood is analytically or computationally intractable. Several ABC methods have been proposed: Monte Carlo Markov BGPChains (MCMC) methods have been developped by Marjoramet al. (2003) and by Bortotet al. (2007) for instance, and sequential methods have been proposed among others by Sissonet al. (2007), Beaumont et al. (2009) and Del Moral et al. (2009). Until now, while ABC-MCMC methods remain the reference, sequential ABC methods have appeared to outperforms them (see for example McKinley et al. (2009) or Sisson et al. (2007)). In this paper a new algorithm combining population-based MCMC methods with ABC requirements is proposed, using an analogy with the Parallel Tempering algorithm (Geyer, 1991). Performances are compared with existing ABC algorithms on simulations and on a real example.\n\nFields\n\nm: MProb\nopts: a Dict of options\ni: current iteration\nchains: An array of BGPChain\nanim: Plots.Animation\ndist_fun: function to measure distance between one evaluation and the next.\n\n\n\n\n\n","category":"type"},{"location":"algo.html#SMM.CI-Tuple{SMM.BGPChain}","page":"Moment Algorithms","title":"SMM.CI","text":"CI(c::BGPChain;level=0.95)\n\nConfidence interval on parameters\n\n\n\n\n\n","category":"method"},{"location":"algo.html#SMM.extendBGPChain!-Tuple{SMM.BGPChain,MAlgoBGP,Int64}","page":"Moment Algorithms","title":"SMM.extendBGPChain!","text":"extendBGPChain!(chain::BGPChain, algo::MAlgoBGP, extraIter::Int64)\n\nStarting from an existing MAlgoBGP, allow for additional iterations by extending a specific chain. This function is used to restart a previous estimation run via restart!\n\n\n\n\n\n","category":"method"},{"location":"algo.html#SMM.restart!-Tuple{MAlgoBGP,Int64}","page":"Moment Algorithms","title":"SMM.restart!","text":"restart!(algo::MAlgoBGP, extraIter::Int64)\n\nStarting from an existing AlgoBGP, restart the optimization from where it stopped. Add extraIter additional steps to the optimization process.\n\n\n\n\n\n","category":"method"},{"location":"algo.html#SMM.summary-Tuple{SMM.BGPChain}","page":"Moment Algorithms","title":"SMM.summary","text":"summary(c::BGPChain)\n\nReturns a summary of the chain. Condensed history\n\n\n\n\n\n","category":"method"},{"location":"algo.html#Statistics.mean-Tuple{SMM.BGPChain}","page":"Moment Algorithms","title":"Statistics.mean","text":"mean(c::BGPChain)\n\nReturns the mean of all parameter values stored on the chain.\n\n\n\n\n\n","category":"method"},{"location":"algo.html#Statistics.median-Tuple{SMM.BGPChain}","page":"Moment Algorithms","title":"Statistics.median","text":"median(c::BGPChain)\n\nReturns the median of all parameter values stored on the chain.\n\n\n\n\n\n","category":"method"},{"location":"algo.html#SMM.BGPChain","page":"Moment Algorithms","title":"SMM.BGPChain","text":"BGPChain\n\nMCMC Chain storage for BGP algorithm. This is the main datatype for the implementation of Baragatti, Grimaud and Pommeret (BGP) in Likelihood-free parallel tempring\n\nFields\n\nevals: Array of Evals\nbest_id: index of best eval.value so far\nbest_val: best eval.value so far\ncurr_val : current value\nprobs_acc: vector of probabilities with which to accept current value\nid: Chain identifier\niter: current iteration\naccepted: Array{Bool} of length(evals)\naccept_rate: current acceptance rate\nacc_tuner: Acceptance tuner. acc_tuner > 1 means to be more restrictive: params that yield a worse function value are less likely to get accepted, the higher acc_tuner is.\nexchanged: Array{Int} of length(evals) with index of chain that was exchanged with\nm: MProb\nsigma: Float64 shock variance\nsigma_update_steps:  update sampling vars every sigma_update_steps iterations. setting sigma_update_steps > maxiter means to never update the variances.\nsigma_adjust_by: adjust sampling vars by sigma_adjust_by percent up or down\nsmpl_iters: max number of trials to get a new parameter from MvNormal that lies within support\nmin_improve: minimally required improvement in chain j over chain i for an exchange move j->i to talk place.\nbatches: in the proposal function update the parameter vector in batches. [default: update entire param vector]\n\n\n\n\n\n","category":"type"},{"location":"algo.html#SMM.allAccepted-Tuple{SMM.BGPChain}","page":"Moment Algorithms","title":"SMM.allAccepted","text":"allAccepted(c::BGPChain)\n\nGet all accepted Evals from a chain\n\n\n\n\n\n","category":"method"},{"location":"algo.html#SMM.best-Tuple{SMM.BGPChain}","page":"Moment Algorithms","title":"SMM.best","text":"best(c::BGPChain) -> (val,idx)\n\nReturns the smallest value and index stored of the chain.\n\n\n\n\n\n","category":"method"},{"location":"algo.html#SMM.computeNextIteration!-Tuple{MAlgoBGP}","page":"Moment Algorithms","title":"SMM.computeNextIteration!","text":"computeNextIteration!( algo::MAlgoBGP )\n\ncomputes new candidate vectors for each BGPChain accepts/rejects that vector on each BGPChain, according to some rule. The evaluation objective functions is performed in parallel, is so desired.\n\nOn each chain c:\ncomputes new parameter vectors\napplies a criterion to accept/reject any new params\nstores the result in BGPChains\nCalls exchangeMoves! to swap chains\n\n\n\n\n\n","category":"method"},{"location":"algo.html#SMM.doAcceptReject!-Tuple{SMM.BGPChain,Eval}","page":"Moment Algorithms","title":"SMM.doAcceptReject!","text":"doAcceptReject!(c::BGPChain,eval_new::Eval)\n\nPerform a Metropolis-Hastings accept-reject operation on the latest Eval and update the sampling variance, if so desired (set via sigma_update_steps in BGPChain constructor.)\n\n\n\n\n\n","category":"method"},{"location":"algo.html#SMM.exchangeMoves!-Tuple{MAlgoBGP}","page":"Moment Algorithms","title":"SMM.exchangeMoves!","text":"exchangeMoves!(algo::MAlgoBGP)\n\nExchange chain i and j with if dist_fun(evi.value,evj.value) is greate than a threshold value c.min_improve. Commonly, this means that we only exchange if j is better by at least c.min_improve.\n\n\n\n\n\n","category":"method"},{"location":"algo.html#SMM.history-Tuple{SMM.BGPChain}","page":"Moment Algorithms","title":"SMM.history","text":"history(c::BGPChain)\n\nReturns a DataFrame with a history of the chain.\n\n\n\n\n\n","category":"method"},{"location":"algo.html#SMM.mysample-Tuple{Distributions.Distribution{Distributions.Multivariate,S} where S<:Distributions.ValueSupport,Float64,Float64,Int64}","page":"Moment Algorithms","title":"SMM.mysample","text":"mysample(d::Distributions.MultivariateDistribution,lb::Vector{Float64},ub::Vector{Float64},iters::Int)\n\nmysample from distribution d until all poins are in support. This is a crude version of a truncated distribution: It just samples until all draws are within the admissible domain.\n\n\n\n\n\n","category":"method"},{"location":"algo.html#SMM.next_eval-Tuple{SMM.BGPChain}","page":"Moment Algorithms","title":"SMM.next_eval","text":"next_eval(c::BGPChain)\n\nComputes the next Eval for chain c:\n\nGet last accepted param \nget a new param via proposal\nevaluateObjective\nAccept or Reject the new value via doAcceptReject!\nStore Eval on chain c.\n\n\n\n\n\n","category":"method"},{"location":"algo.html#SMM.proposal-Tuple{SMM.BGPChain}","page":"Moment Algorithms","title":"SMM.proposal","text":"proposal(c::BGPChain)\n\nGaussian Transition Kernel centered on current parameter value. \n\nMap all k parameters into mu in 01^k.\nupdate all parameters by sampling from MvNormal, N(musigma), where sigma is c.sigma until all params are in 01^k\nMap 01^k back to original parameter spaces.\n\n\n\n\n\n","category":"method"},{"location":"algo.html#SMM.set_acceptRate!-Tuple{SMM.BGPChain}","page":"Moment Algorithms","title":"SMM.set_acceptRate!","text":"set acceptance rate on chain. considers only iterations where no exchange happened.\n\n\n\n\n\n","category":"method"},{"location":"algo.html#SMM.swap_ev_ij!-Tuple{MAlgoBGP,Int64,Int64}","page":"Moment Algorithms","title":"SMM.swap_ev_ij!","text":"replace the current Eval of chain i with the one of chain j\n\n\n\n\n\n","category":"method"},{"location":"index.html#SMM.jl-1","page":"Introduction","title":"SMM.jl","text":"","category":"section"},{"location":"index.html#","page":"Introduction","title":"Introduction","text":"Simulated Method of Moments (SMM) for Julia","category":"page"},{"location":"index.html#","page":"Introduction","title":"Introduction","text":"A package providing supporting infrastructure and algorithms to perform Simulated Method of Moments.","category":"page"},{"location":"index.html#Features-1","page":"Introduction","title":"Features","text":"","category":"section"},{"location":"index.html#","page":"Introduction","title":"Introduction","text":"Fully fledged SMM infrastructure to track moments and function evaluations.\nSupply your own objective function to be optimized.\nOptimization can be carried out in parallel.\nDiagnostic tools illustrating the proposal distribution as well as markov chain statistics.\nIncludes a parellel tempering likelihood-free optimizer using MCMC technology and a coordinate descent optimizer.","category":"page"},{"location":"index.html#","page":"Introduction","title":"Introduction","text":"For some example usage see the Examples page.","category":"page"},{"location":"index.html#Manual-Outline-1","page":"Introduction","title":"Manual Outline","text":"","category":"section"},{"location":"index.html#","page":"Introduction","title":"Introduction","text":"Pages = [\"index.md\",\"eval.md\",\"slices.md\",\"algo.md\",\"metrics.md\",\"examples.md\"]","category":"page"},{"location":"index.html#MProb:-Minimisation/Maximisation-Problems-1","page":"Introduction","title":"MProb: Minimisation/Maximisation Problems","text":"","category":"section"},{"location":"index.html#","page":"Introduction","title":"Introduction","text":"A core object of this library is the MProb type, specifying an optimisation problem.","category":"page"},{"location":"index.html#","page":"Introduction","title":"Introduction","text":"Modules = [SMM]\nPages = [\"mprob.jl\"]","category":"page"},{"location":"index.html#SMM.MProb","page":"Introduction","title":"SMM.MProb","text":"Minimisation Problem: MProb\n\nA moment minimsation problem is defined by an objective function that depends on a vector of unknown parameters params_to_sample, and a set of datamoments moments. The key idea here is the one of simulated method of moments, where we use params_to_sample to simulate a model, some moments of which will be compared to moments from the data.\n\nFields:\n\ninitial_value: initial parameter value as a dict\nparams_to_sample: OrderedDict with lower and upper bounds\nobjfunc: objective function\nobjfunc_opts: options passed to the objective function, e.g. printlevel\nmoments: a dictionary or dataframe of data moments to track\n\nExample:\n\npb    = Dict(p1\" => [0.2,-2,2] , \"p2\" => [-0.2,-2,2] )\nmoms  = DataFrame(name=[\"mu2\",\"mu1\"],value=[0.0,0.0],weight=rand(2))\nm     = MProb() \naddSampledParam!(m,pb) \naddMoment!(m,moms) \nSMM.addEvalFunc!(m,SMM.objfunc_norm)\n\n\n\n\n\n","category":"type"},{"location":"index.html#SMM.addMoment!-Tuple{MProb,String,Any,Any}","page":"Introduction","title":"SMM.addMoment!","text":"addMoment!(m::MProb,name::String,value,weight)\n\n\n\n\n\n","category":"method"},{"location":"index.html#SMM.addMoment!-Tuple{MProb,String,Any}","page":"Introduction","title":"SMM.addMoment!","text":"addMoment!(m::MProb,name::String,value)\n\n\n\n\n\n","category":"method"},{"location":"index.html#SMM.addMoment!-Tuple{MProb,Symbol,Any,Any}","page":"Introduction","title":"SMM.addMoment!","text":"addMoment!(m::MProb,name::Symbol,value,weight)\n\nAdd Moments to an MProb. Adds a single moment to the mprob.\n\nname: the name of the moment as a Symbol value: value of the moment weight: weight in the objective function\n\n\n\n\n\n","category":"method"},{"location":"index.html#SMM.addMoment!-Tuple{MProb,Symbol,Any}","page":"Introduction","title":"SMM.addMoment!","text":"addMoment!(m::MProb,name::Symbol,value)\n\n\n\n\n\n","category":"method"},{"location":"index.html#SMM.addParam!-Tuple{MProb,String,Any}","page":"Introduction","title":"SMM.addParam!","text":"Add initial parameter values to an MProb minimisation problem.\n\n\n\n\n\n","category":"method"},{"location":"index.html#SMM.addParam!-Tuple{MProb,Union{Dict, OrderedDict}}","page":"Introduction","title":"SMM.addParam!","text":"Add initial parameter values to an MProb minimisation problem.\n\nArguments:\n\np: A Dict with (String,Number) pairs\n\n\n\n\n\n","category":"method"},{"location":"index.html#SMM.addSampledParam!","page":"Introduction","title":"SMM.addSampledParam!","text":"Add parameters to be sampled to an MProb.\n\nd: a Dict with a triple (init,lb,ub) as value for each key.\n\n\n\n\n\n","category":"function"},{"location":"index.html#SMM.addSampledParam!-Tuple{MProb,Any,Any,Any,Any}","page":"Introduction","title":"SMM.addSampledParam!","text":"Add parameters to be sampled to an MProb.\n\n\n\n\n\n","category":"method"},{"location":"index.html#SMM.evaluateObjective-Tuple{MProb,Any}","page":"Introduction","title":"SMM.evaluateObjective","text":"evaluateObjective(m::MProb,ev::Eval)\n\nEvaluate the objective function of an MProb at a given Eval.\n\n\n\n\n\n","category":"method"},{"location":"index.html#SMM.evaluateObjective-Tuple{MProb,Union{Dict, OrderedDict}}","page":"Introduction","title":"SMM.evaluateObjective","text":"evaluateObjective(m::MProb,p::Union{Dict,OrderedDict};noseed=false)\n\nEvaluate the objective function of an MProb at a given parameter vector p.  Set noseed to true if you want to generate new random draws for shocks in the objective function (necessary for estimation of standard errors in get_stdErrors, for example)\n\n\n\n\n\n","category":"method"},{"location":"index.html#SMM.mapto_01-Tuple{OrderedCollections.OrderedDict,Array{Float64,1},Array{Float64,1}}","page":"Introduction","title":"SMM.mapto_01","text":"mapto_01(p::OrderedDict,lb::Vector{Float64},ub::Vector{Float64})\n\nmap param to [0,1]\n\n\n\n\n\n","category":"method"},{"location":"index.html#SMM.mapto_ab-Tuple{Array{Float64,1},Array{Float64,1},Array{Float64,1}}","page":"Introduction","title":"SMM.mapto_ab","text":"mapto_ab(p::Vector{Float64},lb::Vector{Float64},ub::Vector{Float64})\n\nmap param from [0,1] to [a,b]\n\n\n\n\n\n","category":"method"},{"location":"index.html#SMM.ms_names-Tuple{MProb}","page":"Introduction","title":"SMM.ms_names","text":"Get the name of moments\n\n\n\n\n\n","category":"method"},{"location":"index.html#SMM.ps2s_names-Tuple{MProb}","page":"Introduction","title":"SMM.ps2s_names","text":"Get sampled parameter names from the MProb\n\n\n\n\n\n","category":"method"},{"location":"index.html#SMM.ps_names-Tuple{MProb}","page":"Introduction","title":"SMM.ps_names","text":"Get all parameter names from the MProb\n\n\n\n\n\n","category":"method"}]
}
